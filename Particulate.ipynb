{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18e2a342-4b4b-4b30-a6f0-6fc397d5c484",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook contains code to combine open data from [`sensor.community`](https://sensor.community/) air quality sensors with wind data from the [Dutch Royal Meteorological Society (KNMI)](https://knmi.nl/). By default it will use the KNMI public API key (the one in the notebook is valid until June 2022, you can [find the latest public API key here](https://developer.dataplatform.knmi.nl/get-started#obtain-an-api-key)). You can also obtain a personal API key very easily, which will not expire (follow the instructions included below the public API key).\n",
    "\n",
    "# Requirements\n",
    "\n",
    "The cell below imports all required modules. All of these should be included in a basic Anaconda Python 3 installation, except for the `mpu` module, which you will need to install from the command line using `pip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "360335cc-7e42-44ab-ac28-ca807a010ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import datetime\n",
    "import pandas\n",
    "import gzip\n",
    "import dateutil.relativedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import mpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaeba7a-d0f4-477b-bc72-3ce798224f4b",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7177ab97-6d07-4f65-bf87-bf9894e6737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNMI API key (replace by your personal key if you have one, this public access key is valid until June 2022)\n",
    "knmi_api_key = \"eyJvcmciOiI1ZTU1NGUxOTI3NGE5NjAwMDEyYTNlYjEiLCJpZCI6ImNjOWE2YjM3ZjVhODQwMDZiMWIzZGIzZDRjYzVjODFiIiwiaCI6Im11cm11cjEyOCJ9\"\n",
    "\n",
    "# Base URL for KNMI open wind data\n",
    "knmi_wind_base_url = \"https://api.dataplatform.knmi.nl/open-data/v1/datasets/windgegevens/versions/1.0/files\"\n",
    "\n",
    "# Directory to cache data downloaded from KNMI; directory will be created automatically if it doesn't exist\n",
    "knmi_cache_dir = \"./knmi_cache\"\n",
    "\n",
    "# Sensor data URL template; parameters: day,day,sensor ID\n",
    "sensor_url_template = \"https://archive.sensor.community/{}/{}_sds011_sensor_{}.csv\"\n",
    "\n",
    "# Directory to write plots to; directory will be created automatically if it doesn't exist\n",
    "plots_dir = \"./plots\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142d0a38-0b35-4d83-a26a-340652aac5b6",
   "metadata": {},
   "source": [
    "# KNMI data fetch\n",
    "\n",
    "The function in the next cell downloads the KNMI open data using the configured API key and loads it into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a05aa3b9-3c0c-4211-81e4-e91e8f8ab965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knmi_wind_data(year, month):\n",
    "    # Cache filename\n",
    "    cache_file = '{}/kis_tow_{:04d}{:02d}.gz'.format(knmi_cache_dir, year, month)\n",
    "    \n",
    "    if not os.path.exists(cache_file):\n",
    "        if not os.path.exists(knmi_cache_dir):\n",
    "            os.makedirs(knmi_cache_dir)\n",
    "        \n",
    "        # Compose URL to fetch a temporary download link from the KNMI API server\n",
    "        month_url = '{}/kis_tow_{:04d}{:02d}.gz/url'.format(knmi_wind_base_url, year, month)\n",
    "    \n",
    "        print('Fetching temporary download URL from {} ...'.format(month_url))\n",
    "    \n",
    "        get_file_url_res = requests.get(month_url, headers={\"Authorization\": knmi_api_key})\n",
    "    \n",
    "        if get_file_url_res.status_code != 200:\n",
    "            print(\"Failed ({})\".format(get_file_url_res.status_code))\n",
    "            return None\n",
    "    \n",
    "        tmp_url = get_file_url_res.json().get(\"temporaryDownloadUrl\", None)\n",
    "\n",
    "        if tmp_url is None:\n",
    "            print('Response from server is missing the attribute \"temporaryDownloadUrl\"')\n",
    "            return None\n",
    "        \n",
    "        print('Fetching data from {} ...'.format(tmp_url))\n",
    "        \n",
    "        get_file_res = requests.get(tmp_url)\n",
    "        \n",
    "        if get_file_res.status_code != 200:\n",
    "            print(\"Fetch failed ({})\".format(get_file_res.status_code))\n",
    "            return None\n",
    "        \n",
    "        # Write file to cache\n",
    "        with open(cache_file, 'wb') as fd:\n",
    "            fd.write(get_file_res.content)\n",
    "            \n",
    "        print('Fetched {} ({:,d} bytes)'.format(cache_file, os.stat(cache_file).st_size))\n",
    "    else:\n",
    "        print('Wind data for {:04d}-{:02d} is cached'.format(year, month))\n",
    "        \n",
    "    # Parse wind data into a Pandas dataframe\n",
    "    widths = []\n",
    "    widths.append(len('DTG                '))\n",
    "    widths.append(len('LOCATION            '))\n",
    "    widths.append(len('NAME                                            '))\n",
    "    widths.append(len('LATITUDE            '))\n",
    "    widths.append(len('LONGITUDE           '))\n",
    "    widths.append(len('ALTITUDE            '))\n",
    "    widths.append(len('FF_SENSOR_10        '))\n",
    "    widths.append(len('FF_10M_10           '))\n",
    "    widths.append(len('DD_10               '))\n",
    "    widths.append(len('DDN_10              '))\n",
    "    widths.append(len('DD_STD_10           '))\n",
    "    widths.append(len('DDX_10              '))\n",
    "    widths.append(len('FF_10M_STD_10       '))\n",
    "    widths.append(len('FX_10M_10           '))\n",
    "    widths.append(len('FX_10M_MD_10        '))\n",
    "    widths.append(len('FX_SENSOR_10        '))\n",
    "    widths.append(len('FX_SENSOR_MD_10     '))\n",
    "    widths.append(len('SQUALL_10           '))\n",
    "    \n",
    "    print('Parsing wind data...')\n",
    "    \n",
    "    df = pandas.read_fwf(cache_file, comment='#', compression='gzip', widths=widths,\\\n",
    "                         parse_dates=[0], infer_datetime_format=True, names=\\\n",
    "                        ['DTG','LOCATION','NAME','LATITUDE','LONGITUDE',\\\n",
    "                         'ALTITUDE','FF_SENSOR_10','FF_10M_10','DD_10',\\\n",
    "                         'DDN_10','DD_STD_10','DDX_10','FF_10M_STD_10',\\\n",
    "                         'FX_10M_10','FX_10M_MD_10','FX_SENSOR_10',\\\n",
    "                         'FX_SENSOR_MD_10','SQUALL_10'])\n",
    "    \n",
    "    print('Loaded DataFrame with {} rows and {} columns'.format(df.shape[0], df.shape[1]))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69add02b-cf93-4c28-9e27-b0c0bd8263b3",
   "metadata": {},
   "source": [
    "# Sensor data fetch\n",
    "\n",
    "The function in the cell below fetches data for the sensor with the specified identifier for the specified month and returns it as a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67771754-861d-45d2-8cfc-e1fb5a0bac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_sensor_data(year, month, sensor_id):\n",
    "    day = datetime.date(year, month, 1)\n",
    "    end_date = day + dateutil.relativedelta.relativedelta(months=+1) - datetime.timedelta(days=1)\n",
    "    \n",
    "    day_frames = []\n",
    "    \n",
    "    print('Fetching sensor data for {:04d}-{:02d} for ID {} from the sensor.community archive'.format(year, month, sensor_id))\n",
    "    \n",
    "    while day <= end_date:\n",
    "        day_url = sensor_url_template.format(day, day, sensor_id)\n",
    "        \n",
    "        print('Fetching data frame from {}'.format(day_url))\n",
    "        \n",
    "        try:\n",
    "            df = pandas.read_csv(day_url, delimiter=';', parse_dates=[5])\n",
    "            day_frames.append(df)\n",
    "        except:\n",
    "            print('Failed, perhaps there is no data for ID {} on {}'.format(sensor_id, day))\n",
    "        \n",
    "        day += datetime.timedelta(days=1)\n",
    "        \n",
    "    df = pandas.concat(day_frames)\n",
    "    \n",
    "    print('Loaded DataFrame with {} rows and {} columns'.format(df.shape[0], df.shape[1]))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19987941-5dc0-4c45-a0c6-ac0fc58dc5cf",
   "metadata": {},
   "source": [
    "# Get wind data for the closest station\n",
    "\n",
    "The function in the cell below takes as input sensor data and fetches wind data for the closest station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8b095550-e99a-4fbc-a3c8-60bda8e8535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_wind_data(year, month, sensor_df):\n",
    "    # Get wind data for the specified month\n",
    "    wind_df = get_knmi_wind_data(year, month)\n",
    "    \n",
    "    if wind_df is None:\n",
    "        print('No wind data for {:04d}-{:02d}'.format(year, month))\n",
    "        return None\n",
    "    \n",
    "    # Drop stations that do not have wind direction information\n",
    "    wind_df = wind_df[wind_df['DD_10'].notna()]\n",
    "    \n",
    "    # Determine the longitude and latitude of the sensor\n",
    "    sensor_pos_df = sensor_df[['lat', 'lon']].drop_duplicates()\n",
    "    sensor_lat = sensor_pos_df['lat'].values[0]\n",
    "    sensor_lon = sensor_pos_df['lon'].values[0]\n",
    "    \n",
    "    print('Sensor is at {},{}'.format(sensor_lat, sensor_lon))\n",
    "    \n",
    "    # Determine wind station locations\n",
    "    wind_lat_lon = wind_df[['LATITUDE','LONGITUDE','LOCATION','NAME']].drop_duplicates()\n",
    "    \n",
    "    dist = 0\n",
    "    station_loc = None\n",
    "    station_name = None\n",
    "    \n",
    "    for index,row in wind_lat_lon.iterrows():\n",
    "        wind_lat = row[\"LATITUDE\"]\n",
    "        wind_lon = row[\"LONGITUDE\"]\n",
    "        \n",
    "        station_to_sensor_dist = mpu.haversine_distance((sensor_lat, sensor_lon), (wind_lat, wind_lon))\n",
    "        \n",
    "        if dist == 0 or station_to_sensor_dist < dist:\n",
    "            station_loc = row[\"LOCATION\"]\n",
    "            station_name = row[\"NAME\"]\n",
    "            dist = station_to_sensor_dist\n",
    "            \n",
    "    print('Closest station to sensor is \"{}\" at distance {:0.1f} km'.format(station_name, dist))\n",
    "    \n",
    "    station_df = wind_df[wind_df.LOCATION == station_loc]\n",
    "    \n",
    "    print('Filtered wind DataFrame with {} rows and {} columns'.format(station_df.shape[0], station_df.shape[1]))\n",
    "    \n",
    "    return station_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806d18e7-fbd6-4dd8-9da9-b743a84eaf3a",
   "metadata": {},
   "source": [
    "# Get combined data for a month\n",
    "\n",
    "The function in the cell below takes a year, month and sensor ID as input and outputs a DataFrame that contains combined wind and sensor data that can be used for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ad71332b-a89b-4345-bc18-2fec434cc478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_month_data(year, month, sensor_id):\n",
    "    # Get sensor data\n",
    "    sensor_df = fetch_sensor_data(year, month, sensor_id)\n",
    "    \n",
    "    # Get wind data\n",
    "    wind_df = get_closest_wind_data(year, month, sensor_df)\n",
    "    \n",
    "    # Start with an empty DataFrame\n",
    "    result_df = pandas.DataFrame(columns=['sensorId', 'hourOfDay','windDirection','windDirectionRadians','pm25_mean','pm25_median', 'pm25_max', 'pm10_mean', 'pm10_median', 'pm10_max'])\n",
    "    \n",
    "    # Iterate over the wind data and match this with sensor data\n",
    "    cur_day = None\n",
    "    \n",
    "    sys.stdout.write('Processing {:04d}-{:02d}: '.format(year, month))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    for index,row in wind_df.iterrows():\n",
    "        # Determine wind time window for this row\n",
    "        start_ts = row['DTG'] - datetime.timedelta(minutes=10)\n",
    "        end_ts = row['DTG']\n",
    "        \n",
    "        # Filter sensor data for this window\n",
    "        sensor_window = sensor_df[(sensor_df['timestamp'] >= start_ts) & (sensor_df['timestamp'] < end_ts)]\n",
    "        \n",
    "        avg_pm25 = sensor_window['P2'].mean()\n",
    "        med_pm25 = sensor_window['P2'].median()\n",
    "        max_pm25 = sensor_window['P2'].max()\n",
    "        \n",
    "        avg_pm10 = sensor_window['P1'].mean()\n",
    "        med_pm10 = sensor_window['P1'].median()\n",
    "        max_pm10 = sensor_window['P1'].max()\n",
    "        \n",
    "        if avg_pm25 > 0 or avg_pm10 > 0:\n",
    "            newRowDict = { 'sensorId': sensor_id, 'yearMonth': '{:04d}-{:02d}'.format(year, month), 'hourOfDay': start_ts.hour, \\\n",
    "                          'windDirection': row['DD_10'], 'windDirectionRadians': numpy.deg2rad(row['DD_10']), \\\n",
    "                          'pm25_mean': avg_pm25, 'pm25_median': med_pm25, 'pm25_max': max_pm25, \\\n",
    "                          'pm10_mean': avg_pm10, 'pm10_median': med_pm10, 'pm10_max': max_pm10 }\n",
    "            result_df = result_df.append(newRowDict, ignore_index=True)\n",
    "\n",
    "        row_day = start_ts.day\n",
    "        \n",
    "        if cur_day != row_day:\n",
    "            sys.stdout.write('{} '.format(row_day))\n",
    "            sys.stdout.flush()\n",
    "            cur_day = row_day\n",
    "            \n",
    "    print('done')\n",
    "    \n",
    "    print('Collected result DataFrame with {} rows and {} columns'.format(result_df.shape[0], result_df.shape[1]))\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a04675-bfaa-4a16-b7a8-90afae0b4572",
   "metadata": {},
   "source": [
    "# Plotting functions\n",
    "\n",
    "The cell below defines the plotting functions. The plotting function `pm_scatter` plots a scatter plot with the wind direction in degrees on the y-axis and the PM sensor value in microgram/cubic metre on the x-axis. The plotting function `pm_scatter_polar` plots a polar plot with the wind direction as angle and the PM sensor value in microgram/cubic metre as value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e738872-98d9-4405-9b20-69df55072c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pm_plot_indiv(df, x, y, c, cmap, ax, title):\n",
    "    df.plot.scatter(x=x, y=y, c=c, colormap=cmap, ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.set(xlabel='',ylabel='')\n",
    "    \n",
    "def pm_scatter(df):\n",
    "    month = df['yearMonth'].values[0]\n",
    "    sensor_id = df['sensorId'].values[0]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20,7.5))\n",
    "    fig.suptitle('Particulate matter distribution versus wind direction ({} for sensor {})'.format(month, sensor_id))\n",
    "    \n",
    "    pm_plot_indiv(df, 'pm25_mean',   'windDirection', 'hourOfDay', 'plasma', axes[0,0], 'PM2.5 mean')\n",
    "    pm_plot_indiv(df, 'pm25_median', 'windDirection', 'hourOfDay', 'plasma', axes[0,1], 'PM2.5 median')\n",
    "    pm_plot_indiv(df, 'pm25_max',    'windDirection', 'hourOfDay', 'plasma', axes[0,2], 'PM2.5 max')\n",
    "    \n",
    "    pm_plot_indiv(df, 'pm10_mean',   'windDirection', 'hourOfDay', 'plasma', axes[1,0], 'PM10 mean')\n",
    "    pm_plot_indiv(df, 'pm10_median', 'windDirection', 'hourOfDay', 'plasma', axes[1,1], 'PM10 median')\n",
    "    pm_plot_indiv(df, 'pm10_max',    'windDirection', 'hourOfDay', 'plasma', axes[1,2], 'PM10 max')\n",
    "    \n",
    "    if not os.path.exists(plots_dir):\n",
    "        os.makedirs(plots_dir)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('{}/pm-vs-wind-{}-{}.pdf'.format(plots_dir, sensor_id, month))\n",
    "    plt.close(fig)\n",
    "    \n",
    "def pm_scatter_polar(df):\n",
    "    month = df['yearMonth'].values[0]\n",
    "    sensor_id = df['sensorId'].values[0]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20,8), subplot_kw=dict(polar=True))\n",
    "    fig.suptitle('Particulate matter distribution versus wind direction ({} for sensor {})'.format(month, sensor_id))\n",
    "    \n",
    "    pm_plot_indiv(df, 'windDirectionRadians', 'pm25_mean',   'hourOfDay', 'plasma', axes[0,0], 'PM2.5 mean')\n",
    "    pm_plot_indiv(df, 'windDirectionRadians', 'pm25_median', 'hourOfDay', 'plasma', axes[0,1], 'PM2.5 median')\n",
    "    pm_plot_indiv(df, 'windDirectionRadians', 'pm25_max',    'hourOfDay', 'plasma', axes[0,2], 'PM2.5 max')\n",
    "    \n",
    "    pm_plot_indiv(df, 'windDirectionRadians', 'pm10_mean',   'hourOfDay', 'plasma', axes[1,0], 'PM10 mean')\n",
    "    pm_plot_indiv(df, 'windDirectionRadians', 'pm10_median', 'hourOfDay', 'plasma', axes[1,1], 'PM10 median')\n",
    "    pm_plot_indiv(df, 'windDirectionRadians', 'pm10_max',    'hourOfDay', 'plasma', axes[1,2], 'PM10 max')\n",
    "    \n",
    "    for ax in axes.flat:\n",
    "        ax.set_theta_direction(-1)\n",
    "        ax.set_theta_zero_location('N')\n",
    "        ax.grid(linewidth=1)\n",
    "        ax.set_xticks(ax.get_xticks().tolist())\n",
    "        ax.set_xticklabels(['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW'])\n",
    "        \n",
    "    if not os.path.exists(plots_dir):\n",
    "        os.makedirs(plots_dir)\n",
    "            \n",
    "    fig.tight_layout()\n",
    "    fig.savefig('{}/pm-vs-wind-polar-{}-{}.pdf'.format(plots_dir, sensor_id, month))\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a316a4e-0e46-4026-8bf2-6ea5cdad7f83",
   "metadata": {},
   "source": [
    "# Putting it all together\n",
    "\n",
    "The code snippet below shows an example of how to put it all together. It creates plots for my sensor (ID 39024) for July to December 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f44663-d316-4ae6-ac84-a393d8433f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching sensor data for 2020-07 for ID 39024 from the sensor.community archive\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-01/2020-07-01_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-02/2020-07-02_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-03/2020-07-03_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-04/2020-07-04_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-05/2020-07-05_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-06/2020-07-06_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-07/2020-07-07_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-08/2020-07-08_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-09/2020-07-09_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-10/2020-07-10_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-11/2020-07-11_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-12/2020-07-12_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-13/2020-07-13_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-14/2020-07-14_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-15/2020-07-15_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-16/2020-07-16_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-17/2020-07-17_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-18/2020-07-18_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-19/2020-07-19_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-20/2020-07-20_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-21/2020-07-21_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-22/2020-07-22_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-23/2020-07-23_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-24/2020-07-24_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-25/2020-07-25_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-26/2020-07-26_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-27/2020-07-27_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-28/2020-07-28_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-29/2020-07-29_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-30/2020-07-30_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-07-31/2020-07-31_sds011_sensor_39024.csv\n",
      "Loaded DataFrame with 38482 rows and 12 columns\n",
      "Wind data for 2020-07 is cached\n",
      "Parsing wind data...\n",
      "Loaded DataFrame with 607104 rows and 18 columns\n",
      "Sensor is at 51.982,5.876\n",
      "Closest station to sensor is \"Deelen locatie A\" at distance 8.1 km\n",
      "Filtered wind DataFrame with 4464 rows and 18 columns\n",
      "Processing 2020-07: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 done\n",
      "Collected result DataFrame with 4191 rows and 11 columns\n",
      "Fetching sensor data for 2020-08 for ID 39024 from the sensor.community archive\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-01/2020-08-01_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-02/2020-08-02_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-03/2020-08-03_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-04/2020-08-04_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-05/2020-08-05_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-06/2020-08-06_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-07/2020-08-07_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-08/2020-08-08_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-09/2020-08-09_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-10/2020-08-10_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-11/2020-08-11_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-12/2020-08-12_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-13/2020-08-13_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-14/2020-08-14_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-15/2020-08-15_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-16/2020-08-16_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-17/2020-08-17_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-18/2020-08-18_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-19/2020-08-19_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-20/2020-08-20_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-21/2020-08-21_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-22/2020-08-22_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-23/2020-08-23_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-24/2020-08-24_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-25/2020-08-25_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-26/2020-08-26_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-27/2020-08-27_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-28/2020-08-28_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-29/2020-08-29_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-30/2020-08-30_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-08-31/2020-08-31_sds011_sensor_39024.csv\n",
      "Loaded DataFrame with 32295 rows and 12 columns\n",
      "Wind data for 2020-08 is cached\n",
      "Parsing wind data...\n",
      "Loaded DataFrame with 607104 rows and 18 columns\n",
      "Sensor is at 51.982,5.876\n",
      "Closest station to sensor is \"Deelen locatie A\" at distance 8.1 km\n",
      "Filtered wind DataFrame with 4464 rows and 18 columns\n",
      "Processing 2020-08: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 done\n",
      "Collected result DataFrame with 4395 rows and 11 columns\n",
      "Fetching sensor data for 2020-09 for ID 39024 from the sensor.community archive\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-01/2020-09-01_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-02/2020-09-02_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-03/2020-09-03_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-04/2020-09-04_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-05/2020-09-05_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-06/2020-09-06_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-07/2020-09-07_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-08/2020-09-08_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-09/2020-09-09_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-10/2020-09-10_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-11/2020-09-11_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-12/2020-09-12_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-13/2020-09-13_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-14/2020-09-14_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-15/2020-09-15_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-16/2020-09-16_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-17/2020-09-17_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-18/2020-09-18_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-19/2020-09-19_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-20/2020-09-20_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-21/2020-09-21_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-22/2020-09-22_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-23/2020-09-23_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-24/2020-09-24_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-25/2020-09-25_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-26/2020-09-26_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-27/2020-09-27_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-28/2020-09-28_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-29/2020-09-29_sds011_sensor_39024.csv\n",
      "Fetching data frame from https://archive.sensor.community/2020-09-30/2020-09-30_sds011_sensor_39024.csv\n",
      "Loaded DataFrame with 40063 rows and 12 columns\n",
      "Wind data for 2020-09 is cached\n",
      "Parsing wind data...\n"
     ]
    }
   ],
   "source": [
    "for month in [7, 8, 9, 10, 11, 12]:\n",
    "    df = get_month_data(year = 2020, month = month, sensor_id = 39024)\n",
    "    \n",
    "    pm_scatter(df)\n",
    "    pm_scatter_polar(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe97244-2b2b-44c4-87ae-044f48294920",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
